---
title: "Exploratory data analysis"
author: "Venkata Battepati"
date: "02/03/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(psych) # Contains the winsor function and other helpful statistical tools
library(tidyverse) # Remember from last homework that dplyr is included in tidyverse
library(gridExtra)
library(corrplot)
library(patchwork)
library(grid)
library(factoextra)
```


Reading datasets

```{r}
control <- read.csv("Sepsis_control_data.csv")
positive <- read.csv("Sepsis_positive_data.csv")
positive$sepsis_group <- NULL
control$sepsis_group <- NULL
head(control)
head(positive)
```

Summary of datasets

```{r}
names <- c('mech_vent' ,'apnea','perfusion','co_ivh_shunt','co_surgical','co_congenital','co_chronic_lung','co_nec','ecmo','uac','cvl','lethargy','temp_threshold','fio2_threshold')
control[,names] <- lapply(control[,names] , factor)
summary(control)
```
```{r}
names <- c('mech_vent' ,'apnea','perfusion','co_ivh_shunt','co_surgical','co_congenital','co_chronic_lung','co_nec','ecmo','uac','cvl','lethargy','temp_threshold','fio2_threshold')
positive[,names] <- lapply(positive[,names] , factor)
summary(positive)
```


Making box and violin for control age vs temp

```{r}
violin_control = ggplot(control, aes(x=age, y= temp))+
  geom_violin(outlier.color="blue")+
  labs(title="age vs temp", x="age", fill="temp")
violin_control
```

```{r}
box_control = ggplot(control, aes(x=age, y= temp))+
  geom_boxplot(outlier.color="blue")+
  labs(title="age vs temp", x="age", fill="temp")
box_control
```

Making box and violin for positive age vs temp

```{r}
violin_positive = ggplot(positive, aes(x=age, y= temp))+
  geom_violin(outlier.color="blue")+
  labs(title="age vs temp", x="age", fill="temp")
violin_positive
```

```{r}
box_positive = ggplot(positive, aes(x=age, y= temp))+
  geom_boxplot(outlier.color="blue")+
  labs(title="age vs temp", x="age", fill="temp")
box_positive
```

Scatter plot of control

```{r}
 attach(control)
omit_control = na.omit(control)
numeric_control = subset(omit_control, select=c(age, temp, weight))
plot(age, numeric_control=100000, main="Scatterplot control",
   xlab="age", ylab="Vitals", pch=19, color=numeric_control)
```

Scatter plot of positive

```{r}
attach(positive)
omit_positive = na.omit(positive)
numeric_positive = subset(omit_positive, select=c(age, temp, weight))
plot(age, numeric_positive=10000000, main="Scatterplot positive",
   xlab="age", ylab="Vitals", pch=19, color=numeric_positive)
```

Combining data sets

```{r}
control$sepsis = 0
positive$sepsis = 1
df = rbind(control,positive)
head(df)
nrow(df)
```

```{r}
names <- c('mech_vent' ,'apnea','perfusion','co_ivh_shunt','co_surgical','co_congenital','co_chronic_lung','co_nec','ecmo','uac','cvl','lethargy','temp_threshold','fio2_threshold','sepsis')
df[,names] <- lapply(df[,names] , factor)
summary(df)
```

```{r}
numeric_df =  select_if(df, is.numeric)
corr_df = cor(numeric_df,use = "complete.obs")
corrplot(corr_df, method = 'circle', title="Correlation plot for all Numeric Variables", mar=c(1,0,1,0))
```

Creating a matrix from most correlated variables

```{r}
plot_data = df[, c('dbp',  'map',  'glucose', 'sbp', 'temp', 'rr')]
```


```{r}
panel.hist <- function(x, ...) {
    usr <- par("usr")
    on.exit(par(usr))
    par(usr = c(usr[1:2], 0, 1.5))
    his <- hist(x, plot = FALSE)
    breaks <- his$breaks
    nB <- length(breaks)
    y <- his$counts
    y <- y/max(y)
    rect(breaks[-nB], 0, breaks[-1], y, col = rgb(0, 1, 1, alpha = 0.5), ...)
}
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...) {
    usr <- par("usr")
    on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    Cor <- cor(x,y,use = "complete.obs")
    txt <- paste0(prefix, format(c(Cor, 0.123456789), digits = digits)[1])
    if(missing(cex.cor)) {
        cex.cor <- 0.4 / strwidth(txt)
    }
    text(0.5, 0.5, txt,
         cex = 1 + cex.cor * Cor) # Resize the text by level of correlation
}
pairs(plot_data, upper.panel = panel.cor,diag.panel = panel.hist,lower.panel = panel.smooth,main = "Scatter plots, histograms, and corr coeff for variables of interest")
```

Creating boxplot for variables

```{r}
box1 = ggplot(df, aes(x = sepsis, y = glucose))+ #choses what dats is used for boxplot
  geom_boxplot()+ #makes boxplot 
  labs(title="Glucose")+
  theme(plot.title = element_text(hjust = 0.5))
box2 = ggplot(df, aes(x = sepsis,y = map))+
  geom_boxplot()+
  labs(title="Mean Arterial Press.")+
  theme(plot.title = element_text(size = 10,hjust = 0.5))
box3 = ggplot(df, aes(x = sepsis,y = temp))+
  geom_boxplot()+
  labs(title="Temperature")+
  theme(plot.title = element_text(hjust = 0.5))
box4 = ggplot(df, aes(x = sepsis,y = rr))+
  geom_boxplot()+
  labs(title="Respiratory Rate")+
  theme(plot.title = element_text(hjust = 0.5))
grid.arrange(box1,box2,box3,box4,
          ncol = 4, top = textGrob("Boxplots for variables of interest")) #creates 1x3 plots
```


Next step: Should we impute or remove all missing values? If impute - which imputation?


Unsupervised Learning - PCA

Center/scale data and prepare PCA

```{r}
# First must convert factors back into numeric values
numeric_df = df
numeric_df[,names] = lapply(numeric_df[,names] , as.numeric)


df_scale = scale(numeric_df[1:36], center = TRUE, scale = TRUE)
pr.out = prcomp(na.omit(df_scale))
summary(pr.out)
```

Scree plot to visualize % variance explained

```{r}
fviz_eig(pr.out, addlabels = TRUE)
```

Elbow visible around PC4 or PC6, but only account for 62% and 72.7% variance, respectively. Displaying eigenvalue scree plot to analyze which PCs have eigenvalue greater than 1.

```{r}
fviz_eig(pr.out, choice = 'eigenvalue')+
  geom_hline(yintercept=1, color = 'red')

# Displaying eigenvalues since scree plot doesn't display all PCs
get_eig(pr.out)
```
The first 11 PCs have eigenvalues greater than 1.

Biplot of PC1 and PC2 to assess what variables contribute the most

```{r}
fviz_pca_biplot(pr.out, label="var", col.ind="cos2", title="Sepsis PCA Biplot")+
  theme_minimal()
```

Seems that the scaling of the data might have skewed our PCA since the binary classification variables retained their end-range values of 0 and 1 while the continuous variables were scaled down to much smaller values between 0-1. Creatinine, however, is a continuous variable that seems to strongly contribute to both PC1 and


Unsupervised Learning - K-means clustering

```{r}
kmeans_sepsis = kmeans(na.omit(df_scale), centers=2)
fviz_cluster(kmeans_sepsis, na.omit(df_scale))+
  labs(title="K=2 Cluster Plot")
```