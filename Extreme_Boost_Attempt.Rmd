---
title: "Extreme_Boost_Attempt"
author: "Denver Bradley"
date: "3/22/2022"
output: pdf_document
---

```{r setup, include=FALSE}
library (readr)
library(dplyr)
library(tidyverse)
library(xgboost)
library(caret)
library(ROCR)
library(mlr)
library(ParamHelpers)
set.seed(42069)
```

Importing data set, adding sepsis, and non sespsis category, and looking at data
```{r}
control_file="https://raw.githubusercontent.com/braden2447/BME-580-Project/main/Sepsis_control_data.csv"
positive_file = "https://raw.githubusercontent.com/braden2447/BME-580-Project/main/Sepsis_positive_data.csv"

control <- read.csv(url(control_file))
positive <- read.csv(url(positive_file))
positive$sepsis_group <- NULL
control$sepsis_group <- NULL
control$sepsis = 0
positive$sepsis = 1
df = rbind(control,positive)
head(df)
```
Look at missingness in data
```{r}
summary(df)
```

Remove capPH
```{r}
df$capPH = NULL
```

Creating missingness category for correlated variables with small missingness (<50%)
```{r}
num_binary = df # Columns 3-9 have most missingness
# Converting NA's to 1 (i.e. missing) and numerical values to 0 (i.e. not missing)
for (i in 3:9) {
  num_binary[,i] = ifelse(is.na(num_binary[,i]) == T,1,0)
}
df_missingCats = num_binary %>% dplyr::select(-c('wbc','hgb', 'platelet_count', 'bicarb', 'glucose'))
colnames(df_missingCats)[3] = "cbc_missingness"
colnames(df_missingCats)[4] = "blood_chem_missingness"
```

Mean imputation on rest of missingness in df
```{r}
# Perform mean imputation on numeric variables
df_meanImp = df_missingCats
for (i in 1:ncol(df_meanImp)) {
  df_meanImp[,i][is.na(df_meanImp[,i])] = mean(df_meanImp[,i], na.rm=TRUE)
}
summary(df_meanImp)
```

Creating training and test set
```{r}
inTrain = createDataPartition(y = df_meanImp$sepsis, p = 0.8, list = FALSE)

training = df_meanImp[inTrain,]

testing = df_meanImp[-inTrain,]
```

Creating y label and x matrix that xgboost can use
```{r}
y_train = training$sepsis
x_train = xgb.DMatrix(as.matrix(training %>% select(-sepsis)),label = y_train)

y_test = testing$sepsis
x_test = xgb.DMatrix(as.matrix(testing %>% select(-sepsis)),label = y_test)
```

Using 5 fold cross val on train set to determine range for nrounds
```{r}
cross_val = xgb.cv(data = x_train, nfold = 5,
                 nrounds = 100, objective = "binary:logistic", metric = list('logloss','auc','aucpr'),prediction = TRUE, verbose = 0, save_models = TRUE)
cross_val
```

```{r}
err = data.frame(cross_val$evaluation_log)
plot(err$iter, err$train_logloss_mean, col = 4, main = 'Log loss mean vs number of iterations', xlab = 'Number of iterations',ylab = 'Log loss mean') 
lines(err$iter, err$test_logloss_mean, col = 'red')
legend('right',legend = c("Train","Test"),col=c(4,2), lty = c(3,1))
```

```{r}
plot(err$iter, err$train_auc_mean, col = 4,ylim = c(0.5,1), main = 'AUC mean vs number of iterations', xlab = 'Number of iterations',ylab = 'AUC mean')
lines(err$iter, err$test_auc_mean, col = 'red')
legend('bottom',legend = c("Train","Test"),col=c(4,2), lty = c(3,1))
```

```{r}
err[err$test_logloss_mean == min(err$test_logloss_mean),]
```
Seems best range for nrounds lies between 5-20 rounds

Tuning the parameters for the model
```{r}
xgb_trcontrol = trainControl(
  method = "cv",
  number = 5,  
  allowParallel = TRUE,
  verboseIter = FALSE,
  classProbs = TRUE,
  summaryFunction = twoClassSummary
)
```

Grid searching with select parameters
```{r}
xgbGrid <- expand.grid(nrounds = c(5,10,15,20),
                       max_depth = c(3,6,10,15),
                       eta = c(0.1,.2,.3,.5),
                       colsample_bytree = 1,
                       gamma=0,
                       min_child_weight = 1,
                       subsample = 1
                      )
```

Searching for parmeters that give highest sensitivity
```{r}
tran = training %>% select(-sepsis)
y = training %>% select(sepsis)
xgb_model = caret::train(
  x = tran, y = as.factor(ifelse( y == 1, 'pos', 'neg')),  
  trControl = xgb_trcontrol,
  method = "xgbTree",
  metric = 'Sens',
  tuneGrid = xgbGrid,
  verbosity = 0
)
```

```{r}
xgb_model
```

Creating model with best nrounds and parameters
```{r}
boost_model = xgb.train(data = x_train,
                 nrounds = xgb_model$bestTune[,'nrounds'],
                 max_depth = xgb_model$bestTune[,'max_depth'],
                 eta = xgb_model$bestTune[,'eta'],
                 objective = "binary:logistic",
                 eval_metric = 'logloss')
```

Looking at feature importance
```{r}
x_training = training %>% select(-sepsis)
importance = xgb.importance(colnames(x_training), model = boost_model)
xgb.plot.importance(importance[1:nrow(importance)])
```
Looking at scores for model. Keeping sensitivity to above .8 like the original paper did in order to compare other values
```{r}
boost_pred = predict(boost_model,x_test)
actual = ifelse(prediction > 0.22, 1, 0)
stats = confusionMatrix(as.factor(actual),as.factor(y_test),positive = '1')
stats
```

AUC plot
```{r}
pred_boost = prediction(boost_pred, y_test)
perf_boost = ROCR::performance(pred_boost,'tpr','fpr')
plot(perf_boost, main = 'ROC curve for XGBOOST model') 
```
AUC score
```{r}
auc_boost = ROCR::performance(pred_boost, measure = "auc") 
auc_boost@y.values[[1]]
```





